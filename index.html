

<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <style>
        a {
            text-decoration: none; /* Î∞ëÏ§Ñ ÏóÜÏï†Í∏∞ */
            color: darkblue; /* ÎßÅÌÅ¨ ÏÉâÏÉÅ ÏÑ§Ï†ï */
        }
        a:hover {
            /*text-decoration: underline; /* ÎßàÏö∞Ïä§ Ïò§Î≤Ñ Ïãú Î∞ëÏ§Ñ Ï∂îÍ∞Ä (ÏÑ†ÌÉù ÏÇ¨Ìï≠) */
	    color: blue;
        }
    </style>

  <title>Sooyoung Kim</title>
  <link rel="icon" type="image/x-icon" href="images/favicon.ico">

  <meta name="author" content="Sooyoung Kim">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px; style="line-height:200%">
      <td style="padding:0px">
	<div class="docs-section" id="about">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;text-align:justify;">
              <p style="text-align: center">
                <strong><font size="6"><name>Sooyoung Kim</name></font></strong>
              </p>
              <p>My research interests lie in <b>Computer Vision</b>, <b>Generative AI</b>, and <b>Human-AI</b>. I am interested in understanding and generating dynamic images including video and 3D computer vision, particularly applications to story based multi-modal media like movies. I aim to discover how humans process and interpret visual stimuli and how to make the model represent human intelligence and the real-world. </p>
	      <p>I received M.S. in <a href="https://bcs.snu.ac.kr/">Brain and Cognitive Sciences</a> at <a href="https://en.snu.ac.kr/index.html">Seoul National University</a>, under the supervision of <a href="https://www.connectomelab.com/team">Prof.Jiook Cha</a>. Since my Master's program, I have been fortunate to be advised by <a href="https://iacs.stonybrook.edu/people/_affiliates/shinjae-yoo.php">Prof.Shinjae Yoo</a> and <a href="https://ywlincq.github.io/">Prof.Yuewei Lin</a> at <a href="https://www.bnl.gov/world/">Brookhaven National Laboratory (BNL)</a>. Previously, I received B.S. in <a href="https://cms.ewha.ac.kr/user/indexMain.action?siteId=cseeng">Computer Science and Engineering</a> at <a href="https://www.ewha.ac.kr/ewhaen/index.do">Ewha Womans University</a>. </p>
              <p>I will be applying for a PhD in the 2025 cycle!</p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/profile.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/profile.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>

	<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
	<div class="docs-section" id="info">
	  <tr>
	    <td style="text-align:justify;">
	      <p style="text-align: center">
		<a href="mailto:rlatndud0513@snu.ac.kr">rlatndud0513@snu.ac.kr</a> &nbsp/&nbsp
		<a href="data/CV.pdf">CV</a> &nbsp/&nbsp
		<a href="https://github.com/Sooyyoungg">GitHub</a> &nbsp/&nbsp
		<a href="https://www.linkedin.com/in/swimming-whale/">LinkedIn</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?hl=en&user=OR86qUIAAAAJ">Google Scholar</a>
              </p>
	    </td>
	  </tr>
	</div>
	</tbody></table>
	</div>


        <!-- ========== News ========== -->
	<div class="docs-section" id="news">
	  <strong><font size="5"><h5>News</h5></font></strong>
	  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
	        <tr>
	            <td width="80" style="color:#fc83a6;font-weight: bold;vertical-align: top;">Oct 2024</td>
	            <td>Our work, "The Recollection of Your Most Cherished Experiences utilizing AI and Neural Signals" will be presented at the Tech to Art (TAP) International Conference Prequel Exhibition, the ART DIFFUSION.</td>
	        </tr>
	        <tr>
	            <td width="80" style="color:#fc83a6;font-weight: bold;vertical-align: top;">Oct 2024</td>
	            <td>Our team won <b>the GRAND prize</b> üèÖ at the AI & Art Hackathon.</td>
	        </tr>
		<tr>
	            <td width="80" style="color:#fc83a6;font-weight: bold;vertical-align: top;">Oct 2024</td>
	            <td>Started working as an AI research advisor at <a href="https://www.planningo.io/">Planningo</a> via AI research Partnership.</td>
	        </tr>
		<tr>
	            <td width="80" style="color:#fc83a6;font-weight: bold;vertical-align: top;">Sep 2024</td>
	            <td>Selected to participate in the AI x Art Hackathon hosted by the AI Art Research Center in Seoul, Korea.</td>
	        </tr>
		<tr>
	            <td width="80" style="color:#fc83a6;font-weight: bold;vertical-align: top;">Aug 2024</td>
	            <td>Invited for a talk on the brain decoding project at Seoul National University.</td>
	        </tr>
		<tr>
	            <td width="80" style="color:#fc83a6;font-weight: bold;vertical-align: top;">Dec 2023</td>
	            <td>Our <a href="https://aesfa-nst.github.io/AesFA/">AesFA</a> paper got accepted to <b><a href="https://aaai.org/aaai-24-conference/">AAAI 2024</a></b>.</td>
	        </tr>
		<tr>
	            <td width="80" style="color:#fc83a6;font-weight: bold;vertical-align: top;">Aug 2023</td>
	            <td>I received M.S. at Seoul National University. I will continue doing research at <a href="https://www.connectomelab.com/">ConnectomeLab</a>.</td>
	        </tr>
	    </table>
	
	  <div class="row no-gutters">
	    <div class="col-12 col-md-12 text-md-left">
	      <b class="bbold", style="color:#fc83a6;">Oct 2024</b>&nbsp;&nbsp;&nbsp;&nbsp;
	      Our work, "The Recollection of Your Most Cherished Experiences utilizing AI and Neural Signals" will be presented at the Tech to Art (TAP) International Conference Prequel Exhibition, the ART DIFFUSION.
	    </div>
	  </div>
	  <div class="row no-gutters">
	    <div class="col-12 col-md-12 text-md-left">
	      <b class="bbold", style="color:#fc83a6;">Oct 2024</b>&nbsp;&nbsp;&nbsp;&nbsp;
	      Our team won <b>the GRAND prize</b> üèÖ at the AI & Art Hackathon.
	    </div>
	  </div>
	  <div class="row no-gutters">
	    <div class="col-12 col-md-12 text-md-left">
	      <b class="bbold", style="color:#fc83a6;">Oct 2024</b>&nbsp;&nbsp;&nbsp;&nbsp;
	      Started working as an AI research advisor at <a href="https://www.planningo.io/">Planningo</a> via AI research Partnership.
	    </div>
	  </div>
	  <div class="row no-gutters">
	    <div class="col-12 col-md-12 text-md-left">
	      <b class="bbold", style="color:#fc83a6;">Sep 2024</b>&nbsp;&nbsp;&nbsp;&nbsp;
	      Selected to participate in the AI x Art Hackathon hosted by the AI Art Research Center in Seoul, Korea.
	    </div>
	  </div>
	  <div class="row no-gutters">
	    <div class="col-12 col-md-12 text-md-left">
	      <b class="bbold", style="color:#fc83a6;">Aug 2024</b>&nbsp;&nbsp;&nbsp;&nbsp;
	      Invited for a talk on the brain decoding project at Seoul National University.
	    </div>
	  </div>
	  <div class="row no-gutters">
	    <div class="col-12 col-md-12 text-md-left">
	      <b class="bbold", style="color:#fc83a6;">Dec 2023</b>&nbsp;&nbsp;&nbsp;&nbsp;
	      Our <a href="https://aesfa-nst.github.io/AesFA/">AesFA</a> paper got accepted to <b><a href="https://aaai.org/aaai-24-conference/">AAAI 2024</a></b>.
	    </div>
	  </div>
	  <div class="row no-gutters">
	    <div class="col-12 col-md-12 text-md-left">
	      <b class="bbold", style="color:#fc83a6;">Aug 2023</b>&nbsp;&nbsp;&nbsp;&nbsp;
	      I received M.S. at Seoul National University. I will continue doing research at <a href="https://www.connectomelab.com/">ConnectomeLab</a>.
	    </div>
	  </div>
	  <br>
	</div>
	

	      
	<!-- ========== Research In Progress ========== -->
	<div class="docs-section" id="research_in_progress">
	<strong><font size="5"><h5>Research In Progress</h5></font></strong>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

	  <!--  Brain decoding  -->
	      <tr>
		<td style="padding:2%;width:25%;vertical-align:middle">
		  <img src='images/brain_decoding.jpg' width="100%" height="auto">
		</td>
		<td style="padding:2%;width:75%;vertical-align:middle">
		  <strong><papertitle>Visual Attention Guidance Enables A Composable Brain-To-Image Decoding</papertitle></strong>
		  <div style="line-height:20%; font size=1"><br></div>
		  <u><strong><span style="font-size: 15px">Sooyoung Kim*</span></strong></u>, Joonwoo Kwon*, Mincheol Park*, Jeongwoo Seo, <a href="http://escal.yonsei.ac.kr/professor.html">Won Woo Ro</a>, Shinjae Yoo, <a href="https://scholar.google.com/citations?user=E6emHhkAAAAJ&hl=en">Suhyun Kim</a>, <a href="https://ywlincq.github.io/">Yuewei Lin</a>, <a href="https://www.connectomelab.com/team">Jiook Cha</a>
		  <br>
		  <div style="line-height:60%; font size=1"><br></div>
		  <font size="2">
		  We have developed a new brain-to-image decoding model that allows composable prompt modulation using brain signals for the first time. According to the two-streams hypothesis, we correlate ventral and dorsal pathway in the brain to ‚Äòwhat‚Äô and ‚Äòwhere‚Äô information in images different from previous research to reconstruct what people see from functional MRI. We propose a unified brain encoding module for two visual pathways and a new framework that guides the model to the location and identity of objects from the brain based on diffusion models. Our brain-induced attention guidance directly modifies cross-attention layers of LDM at inference without further fine-tuning.
		  </font>
		</td>
	      </tr> 
	
		
	  <!--  AesPHA  -->
	      <tr>
		<td style="padding:2%;width:25%;vertical-align:middle">
		  <img src='images/aespha.jpg' width="100%" height="auto">
		</td>
		<td style="padding:2%;width:75%;vertical-align:middle">
		  <strong><papertitle>AesPHA: An Aesthetic PHysics-Aware Neural Style Transfer</papertitle></strong>
		  <div style="line-height:20%; font size=1"><br></div>
		  Joonwoo Kwon*, <u><strong><span style="font-size: 15px">Sooyoung Kim*</span></strong></u>, Heehwan Wang*, Jinwoo Yi*, Shinjae Yoo, <a href="https://ywlincq.github.io/">Yuewei Lin</a>, <a href="https://www.connectomelab.com/team">Jiook Cha</a>
		  <br>
		  <div style="line-height:60%; font size=1"><br></div>
		  <font size="2">
		  Developed a unique neural style transfer method that effectively captures the style information from the pre-trained fluid-simulation field, utilizing a new style encoding approach that harnesses the chaotic characteristics of the Lorenz system.
		  </font>
		</td>
	      </tr> 

	  <!--  Planningo  -->
	      <tr>
		<td style="padding:2%;width:25%;vertical-align:middle">
		  <img src='images/planningo.jpg' width="100%" height="auto">
		</td>
		<td style="padding:2%;width:75%;vertical-align:middle">
		  <strong><papertitle>Advancing Photio: An AI-based service for product photography</papertitle></strong>
		  <br>
		  Planningo: Transform the landscape of advertising photography and commercial videography
		  <div style="line-height:60%; font size=1"><br></div>
		  <font size="2">
		  I am expected to serve as an AI researcher and consultant starting Oct. 2024, with an AI research partnership with <a href="https://www.seoulaihub.kr/eng1/index2.asp">Seoul AI Hub</a>. I aim to advance an AI-based service Photio by resolving the incongruity between AI-generated backgrounds and original commercial products.
		  <br>
		  /* We develop AI technologies that generate background images or videos corresponding to products. We consider the illumination and position of products for authentic outcomes. Furthermore, to advertise efficiently as an alternative to traditional promotional photography, we should provide various styles of backgrounds with short inference time. Our techniques are applicable in various domains such as advertising, art, film, and social media. */
		  </font>
		</td>
	      </tr> 

		
            </tbody>
	  </table>
	</div>
	      
	<!-- ========== Publications ========== -->
	<div class="docs-section" id="publications">
	<strong><font size="5"><h5>Publications</h5></font></strong>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

	  <!--  MRI Synthesis  -->
	      <tr>
		<td style="padding:2%;width:25%;vertical-align:middle">
		  <img src='images/mri_synthesis.jpg' width="100%" height="auto">
		</td>
		<td style="padding:2%;width:75%;vertical-align:middle">
		  <strong><papertitle>A Rapid and Precise Cross-modal Magnetic Resonance Imaging Synthesis using Multi-scale Structural Brain Similarity</papertitle></strong>
		  <div style="line-height:20%; font size=1"><br></div>
		  <u><strong><span style="font-size: 15px">Sooyoung Kim*</span></strong></u>, Joonwoo Kwon*, Junbeom Kwon, Sangyoon Bae, <a href="https://ywlincq.github.io/">Yuewei Lin</a>, Shinjae Yoo, <a href="https://www.connectomelab.com/team">Jiook Cha</a>
		  <br>
		  <em> Preprint, 2024 </em> <br>
		</td>
	      </tr> 
		
	  <!--  AesFA  -->
	      <tr>
		<td style="padding:2%;width:25%;vertical-align:middle">
		  <img src='images/aesfa.jpg' width="100%" height="auto">
		</td>
		<td style="padding:2%;width:75%;vertical-align:middle">
		  <strong><papertitle>AesFA: An Aesthetic Feature-Aware Arbitrary Neural Style Transfer</papertitle></strong>
		  <div style="line-height:20%; font size=1"><br></div>
		  Joonwoo Kwon*, <u><strong><span style="font-size: 15px">Sooyoung Kim*</span></strong></u>, Shinjae Yoo, <a href="https://ywlincq.github.io/">Yuewei Lin</a>, <a href="https://www.connectomelab.com/team">Jiook Cha</a>
		  <br>
		  <em> AAAI, 2024 (23.75% acceptance rate) </em> <br>
		  <a href="https://arxiv.org/abs/2312.05928">ArXiv</a>
		  /
		  <a href="https://aesfa-nst.github.io/AesFA/">Project page</a>
		  /
		  <a href="https://github.com/Sooyyoungg/AesFA">Code</a>
		  <p></p>
		</td>
	      </tr> 
		
	  <!--  Textbook  -->
	      <tr>
		<td style="padding:2%;width:25%;vertical-align:middle">
		  <img src='images/textbook.jpg' width="100%" height="auto">
		</td>
		<td style="padding:2%;width:75%;vertical-align:middle">
		  <strong><papertitle>Designing Software Creation: Using UML Diagrams</papertitle></strong>
		  <div style="line-height:20%; font size=1"><br></div>
		  <Participated as an assistant author.
		  <br>
		  <em>Published textbook</em>, 2023
		  <br>
		  <a href="https://books.google.co.kr/books/about/%EC%86%8C%ED%94%84%ED%8A%B8%EC%9B%A8%EC%96%B4_%EC%B0%BD%EC%9D%98_%EC%84%A4%EA%B3%84_UML%EB%8B%A4%EC%9D%B4.html?id=EdXKEAAAQBAJ&redir_esc=y">Book</a>
		</td>
	      </tr> 

        </tbody></table>
	</div>


	<!-- ========== Projects ========== -->
	<div class="docs-section" id="research_in_progress">
	<strong><font size="5"><h5>Projects</h5></font></strong>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

	  <!--  AI x Art Hackathon  -->
	      <tr>
		<td style="padding:2%;width:25%;vertical-align:middle">
		  <img src='images/ai_art.jpg' width="100%" height="auto">
		</td>
		<td style="padding:2%;width:75%;vertical-align:middle">
		  <strong><papertitle>The Recollection of Your Most Cherished Experiences utilizing AI and Neural Signals</papertitle></strong>
		  <br>The Grand Prize üèÖ at AI & Art Hackathon, AI Art Research Center, SNU
		  <div style="line-height:20%; font size=1"><br></div>
		  <u><strong><span style="font-size: 15px">Sooyoung Kim</span></strong></u>, Joonwoo Kwon, Heehwan Wang, Jinwoo Yi
		  <br>
		  <a href="data/ai_art.pdf">Presentation Slide</a>
		  <br>
		  <div style="line-height:60%; font size=1"><br></div>
		  <font size="2">
		  We designed an AI framework that generates video with music from memory. We aimed to materialize cherished memories via the video. The inputs of the model were electroencephalogram (EEG) signals, text prompts, and sketches from users who were recalling the memory while listening to the music. We processed the EEG signals by using our pre-trained emotion decoder to obtain how the users felt about the memories. Then, according to how emotions changed over time, we manipulated the music by using Music Gen. We also analyzed the proportion of good and negative emotions, subsequently creating emotion text prompts that were integrated into the input text to guide emotions to the model. We utilized Stable Diffusion to create videos accompanied by music that evoke emotions tied to the users' memories. We ultimately secured the Grand prize!
		  </font>
		</td>
	      </tr> 

	  <!--  SAIT  -->
	      <tr>
		<td style="padding:2%;width:25%;vertical-align:middle">
		  <img src='images/sait.jpg' width="100%" height="auto">
		</td>
		<td style="padding:2%;width:75%;vertical-align:middle">
		  <strong><papertitle>Samsung Advanced Institute of Technology Research Capstone</papertitle></strong>
		  <div style="line-height:20%; font size=1"><br></div>
		  <u><strong><span style="font-size: 15px">Sooyoung Kim</span></strong></u>, Joonwoo Kwon
		  <br>
		  <a href="data/sait.pdf">Project slide</a> / <a href="https://github.com/Sooyyoungg/SAIT">Code</a>
		  <br>
		  <div style="line-height:60%; font size=1"><br></div>
		  <font size="2">
		  We developed an Image-to-Image Translation model that synthesizes 3D depth maps from 2D Scanning Electron Microscope (SEM) images to ensure that semiconductors are produced as intended.
		  </font>
		</td>
	      </tr> 

	   <!--  Mitigating Background Bias  -->
	      <tr>
		<td style="padding:2%;width:25%;vertical-align:middle">
		  <img src='images/background_bias.jpg' width="100%" height="auto">
		</td>
		<td style="padding:2%;width:75%;vertical-align:middle">
		  <strong><papertitle>Mitigating Unwanted Background Biases with Background Data Augmentation</papertitle></strong>
		  <div style="line-height:20%; font size=1"><br></div>
		  Jaeheyoung Jeon, <u><strong><span style="font-size: 15px">Sooyoung Kim</span></strong></u>, Jaehwan Lim
		  <br>
		  <a href="data/background_bias.pdf">Paper</a> / <a href="https://github.com/Sooyyoungg/MLVU_data_augmentation">Code</a>
		  <br>
		  <div style="line-height:60%; font size=1"><br></div>
		  <font size="2">
		  We conducted background augmentation techniques using various backgrounds (RGB, black, mean, and human-selected) during training to reduce biases in image classification and object detection.
		  </font>
		</td>
	      </tr> 

	  <!--  Capstone  -->
	      <tr>
		<td style="padding:2%;width:25%;vertical-align:middle">
		  <img src='images/ai_cctv.jpg' width="100%" height="auto">
		</td>
		<td style="padding:2%;width:75%;vertical-align:middle">
		  <strong><papertitle>A Real-Time Face Detecting AI Surveillance Camera</papertitle></strong>
		  <div style="line-height:20%; font size=1"><br></div>
		  <u><strong><span style="font-size: 15px">Sooyoung Kim</span></strong></u>, Heajin Lee, Suyeon Kim
		  <br>
		  <a href="https://docs.google.com/presentation/d/1C09tdaitmpU3AXYkY608mx4C1ddftSKv/edit?usp=sharing&ouid=105194653391698211161&rtpof=true&sd=true">Presentation slide</a> / <a href="https://github.com/SuyeonKim1702/AI_CCTV">Code1</a> / <a href="https://github.com/leeheajin/AI_CCTV_2">Code2</a> / <a href="data/ai_cctv.pdf">Poster</a> / <a href="data/ai_cctv_video.mp4">Video</a>
		  <br>
		  <div style="line-height:60%; font size=1"><br></div>
		  <font size="2">
		  We developed a smartphone application that identifies the faces of individuals in front of a household and notifies users of the presence of unknown persons in real-time¬†via a camera affixed to the door.
		  </font>
		</td>
	      </tr> 

		
        </tbody></table>
	</div>


	<!-- ========== Honors & Awards ========== -->
	<div class="docs-section" id="honor and awards">
	  <strong><font size="5"><h5>Honors & Awards</h5></font></strong>
	  <div class="row no-gutters">
	    <div class="col-12 col-md-12 text-md-left">
	      <li><b>Grand Prize at AI x Art Hackathon</b>, Oct 2024</li>
	    </div>
	  </div>
	  <div class="row no-gutters">
	    <div class="col-12 col-md-12 text-md-left">
	      <li><b>BrainKorea21 Four Scholarship</b>, 2021‚Äì2022</li>
	    </div>
	  </div>
	  <div class="row no-gutters">
	    <div class="col-12 col-md-12 text-md-left">
	      <li><b>2020 4th Seoul Innovation Challenge</b>, Jan 2020 ‚Äì Sep 2020</li>
	    </div>
	  </div>
	  <div class="row no-gutters">
	    <div class="col-12 col-md-12 text-md-left">
	      <li><b>The 9th Business Plan Contest</b>, Mar 2019 ‚Äì Dec 2019</li>
	    </div>
	  </div>
	  <div class="row no-gutters">
	    <div class="col-12 col-md-12 text-md-left">
	      <li><b>EWHA Scholarship</b>, 2018-2020</li>
	    </div>
	  </div>
	  <div class="row no-gutters">
	    <div class="col-12 col-md-12 text-md-left">
	      <li><b>EWHA Admissions Scholarship (full tuition for a year)</b> - Awarded to the <b>top 10%</b> of students, 2017</li>
	    </div>
	  </div>
	  <br>
	</div>

	      

	<!-- ========== About Myself ========== -->
	<div class="docs-section" id="about myself">
	<strong><font size="5"><h5>About Myself</h5></font></strong>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
	      <tr>
		<td style="padding:2%;width:25%;vertical-align:middle">
		  <img src='images/about_myself.jpg' width="100%" height="auto">
		</td>
		<td style="padding:2%;width:75%;vertical-align:middle">
		  I like swimming a lot, as my first name "ÏàòÏòÅ; Sooyoung" sounds the same as "swimming" in Korean.<br><br>
	      	  I also love movies and dramas with dynamic stories, especially I am a big fan of Brooklyn Nine-Nine, an American comedy series about detectives who police the NYPD's 99th Precinct. The most intriguing thing is to hear how people perceive stories that are open to various interpretations.
		</td>
	      </tr> 

        </tbody></table>
	</div>
		
	<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  Last updated on October 2, 2024
		  <br>
		  Referred to template taken from <a href="https://jonbarron.info/">here</a>.
                </p>
              </td>
            </tr>
          </tbody></table>
	      
        </td>
      </tr>
    </table>

    </tbody>
  </table>

</body>

</html>
